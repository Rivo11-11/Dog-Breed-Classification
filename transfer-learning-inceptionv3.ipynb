{"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7327,"databundleVersionId":861871,"sourceType":"competition"},{"sourceId":100896,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":84626,"modelId":108862}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style =\"font-family:Trebuchet MS; background-color : #f8f0fa; border-left: 5px solid #1b4332; padding: 12px; border-radius: 50px 50px;\">\n    <h2 style=\"color: #1b4332; font-size: 48px; text-align: center;\"><b> Dog Bread Classification Using Transfer Learning\n </b></h2>","metadata":{}},{"cell_type":"markdown","source":"# Images Exploration & Analysis","metadata":{"id":"vxTy4pcY832v"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport matplotlib.image as mpimg\nimport cv2\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential,Model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Activation, BatchNormalization,Dense, Dropout,GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","metadata":{"id":"yCkZcNgJ4bMs","execution":{"iopub.status.busy":"2024-08-25T09:25:08.863472Z","iopub.status.idle":"2024-08-25T09:25:21.766602Z","shell.execute_reply.started":"2024-08-25T09:25:08.863887Z","shell.execute_reply":"2024-08-25T09:25:21.764608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = pd.read_csv(\"/kaggle/input/dog-breed-identification/labels.csv\")\nlabels.head()","metadata":{"id":"vTT934wc5mBL","outputId":"79afbace-f95e-4e97-885d-1a12e36c3ebd","execution":{"iopub.status.busy":"2024-08-25T09:25:21.767306Z","iopub.status.idle":"2024-08-25T09:25:21.767639Z","shell.execute_reply.started":"2024-08-25T09:25:21.767486Z","shell.execute_reply":"2024-08-25T09:25:21.767499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels.shape","metadata":{"id":"8BGLjY0u8v1L","outputId":"ac884975-86a5-4b3a-9820-66547a0927ed","execution":{"iopub.status.busy":"2024-08-25T09:25:21.769385Z","iopub.status.idle":"2024-08-25T09:25:21.769738Z","shell.execute_reply.started":"2024-08-25T09:25:21.769562Z","shell.execute_reply":"2024-08-25T09:25:21.769576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv('/kaggle/input/dog-breed-identification/sample_submission.csv')","metadata":{"id":"JHxP8ZZy5RLu","execution":{"iopub.status.busy":"2024-08-25T09:25:21.770593Z","iopub.status.idle":"2024-08-25T09:25:21.770953Z","shell.execute_reply.started":"2024-08-25T09:25:21.770779Z","shell.execute_reply":"2024-08-25T09:25:21.770794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.head()","metadata":{"id":"2CeP-5-15xC-","outputId":"4ed510a3-f275-464b-e5f4-9da30aec7017","execution":{"iopub.status.busy":"2024-08-25T09:25:21.772445Z","iopub.status.idle":"2024-08-25T09:25:21.772777Z","shell.execute_reply.started":"2024-08-25T09:25:21.772616Z","shell.execute_reply":"2024-08-25T09:25:21.772630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"breed_counts = labels['breed'].value_counts()\n\n\ntop_10 = breed_counts.head(10)\n\n\nbottom_10 = breed_counts.tail(10)\n\nfig, axes = plt.subplots(1, 2, figsize=(20, 8))\n\n\nsns.barplot(y=top_10.index, x=top_10.values, orient='h', ax=axes[0])\naxes[0].set_title('Distribution of Top 10 Breeds')\naxes[0].set_xlabel('Number of Images')\naxes[0].set_ylabel('Breed')\n\nsns.barplot(y=bottom_10.index, x=bottom_10.values, orient='h', ax=axes[1])\naxes[1].set_title('Distribution of Least 10 Breeds')\naxes[1].set_xlabel('Number of Images')\naxes[1].set_ylabel('Breed')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"id":"MoBjo0fI-aJt","outputId":"2f62579d-4e04-4783-9849-4a0d8f9a4128","execution":{"iopub.status.busy":"2024-08-25T09:25:21.774125Z","iopub.status.idle":"2024-08-25T09:25:21.774496Z","shell.execute_reply.started":"2024-08-25T09:25:21.774313Z","shell.execute_reply":"2024-08-25T09:25:21.774326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_dir_train = '/kaggle/input/dog-breed-identification/train'\nimage_dir_test  = '/kaggle/input/dog-breed-identification/test'\nimage_files_train = [f for f in os.listdir(image_dir_train) if f.endswith('.jpg')]\nimage_files_test = [f for f in os.listdir(image_dir_test) if f.endswith('.jpg')]\n\nimage_files_train[:5]\n","metadata":{"outputId":"1f9d611e-a3e6-4585-a844-52b9d3613b63","id":"YCCFW87dEowt","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**labels length = images_files length**","metadata":{"id":"xCYTo-RfFjje"}},{"cell_type":"code","source":"len(image_files_train)","metadata":{"id":"hcokpqzeFAlL","outputId":"5fe1f57f-1303-41a0-afe1-3f216ac8e5e5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(image_files_test)","metadata":{"id":"-y9drruJJp8h","outputId":"4842d653-4ff0-4c33-e6d1-d674c622cb00","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_random_images(dir,image_files,num_samples=5):\n\n    sample_images = random.sample(image_files, num_samples)\n    fig, axes = plt.subplots(1, num_samples, figsize=(num_samples * 3, 5))\n\n    for i, image_file in enumerate(sample_images):\n        img_path = os.path.join(dir, image_file)\n        img = mpimg.imread(img_path)\n\n        axes[i].imshow(img)\n        axes[i].axis('off')\n        axes[i].set_title(image_file.split('.')[0], fontsize=10)\n\n    plt.tight_layout(w_pad=2)\n    plt.show()\n\ndisplay_random_images(image_dir_train,image_files_train,num_samples=5)\n","metadata":{"id":"XjuL6a7uBTIx","outputId":"2c56faa1-4be4-43a2-db11-40254d9c6c07","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**display some of the test images**","metadata":{"id":"Hd4CRsTPGxva"}},{"cell_type":"code","source":"display_random_images(image_dir_test,image_files_test,num_samples=5)","metadata":{"id":"yxNsOWuzJGAl","outputId":"e826db2f-4680-474f-d8e3-74e66ef930d0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Label Encoder on Labels**","metadata":{"id":"NcQhvozPAsSW"}},{"cell_type":"code","source":"label_encoder = LabelEncoder()\nlabels['breed_label'] = label_encoder.fit_transform(labels['breed'])\n","metadata":{"id":"BuUGFvNP7VbA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_value = labels['breed_label'].max()\nmin_value = labels['breed_label'].min()\n\nprint(f\"Maximum value: {max_value}\")\nprint(f\"Minimum value: {min_value}\")\n","metadata":{"id":"WQWkVGlW9Mna","outputId":"905f79c8-95ad-4584-cbb9-41e8708396b1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels.head()","metadata":{"id":"5IQLUgESLIUY","outputId":"b80806e3-05ab-4877-d6e8-5422884c48ff","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels['breed_label'][0]","metadata":{"id":"4Qs3UcmL-ojq","outputId":"de368855-84b0-4e23-e6f7-29ca2e53ac7e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels['breed'][0]","metadata":{"id":"oA0WQ1a9-g97","outputId":"94a5ef00-aee1-448d-f4a2-81eee924fe56","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data PreProcessing","metadata":{"id":"Rhu4b4bbSIpd"}},{"cell_type":"markdown","source":"create a dictionary to map breeds to labels","metadata":{"id":"VKAclsQKbB_5"}},{"cell_type":"code","source":"class_names_label = dict(zip(label_encoder.transform(label_encoder.classes_),label_encoder.classes_))\n","metadata":{"id":"d_pc_crwQgTp","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k,v in class_names_label.items():\n  print( str(k) + ': ' + v)\n  if k == 5 :\n    break\n\n\n","metadata":{"id":"HTDx8332ayKy","outputId":"f6cb2a72-2e97-484e-f157-5f3619c4082a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = (224, 224)\n\ndef load_data(image_dir_train,  labels_df):\n    \"\"\"\n    Load and preprocess the data:\n    - Train images and their labels.\n    - Test images for evaluation.\n    \"\"\"\n\n    def process_images(image_dir):\n        images = []\n        print(\"Loading images from {}\".format(image_dir))\n        for image_file in tqdm(os.listdir(image_dir)):\n            img_path = os.path.join(image_dir, image_file)\n\n            # Open and resize the image\n            image = cv2.imread(img_path)\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n            image = cv2.resize(image, IMAGE_SIZE)\n\n            images.append(image)\n\n        return np.array(images, dtype='float32')\n\n    # Process train images and labels\n    train_images = process_images(image_dir_train)\n    labels = []\n    for image_file in tqdm(os.listdir(image_dir_train)):\n        image_id = image_file.split('.')[0]\n        label = labels_df.loc[labels_df['id'] == image_id, 'breed_label'].values[0]\n        labels.append(label)\n    train_labels = np.array(labels, dtype='int32')\n    return train_images, train_labels\n\n\n\ntrain_images, train_labels= load_data(image_dir_train,labels)\nprint(f\"Train images shape: {train_images.shape}\")\nprint(f\"Train labels shape: {train_labels.shape}\")\n# print(f\"Test labels shape: {test_images.shape}\")","metadata":{"id":"ATmOAjtka2MT","outputId":"50e23248-3a98-4eb6-fed3-d3ee752b2841","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images[0]\n","metadata":{"id":"msdUElLaftI3","outputId":"25249bf1-b31f-4a67-8ba6-5ecb58e8adf4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max(train_labels),min(train_labels),len(train_labels)","metadata":{"id":"k9kaUXdHli2s","outputId":"13befbc2-79ad-4ce6-8ede-be271c317251","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_breed = \"shih-tzu\" \ntarget_label = labels[labels['breed'] == 'shih-tzu'].iloc[0, 2] \ncount = 0  \nmax_images = 10 \nnum_columns = 5  # Number of columns in the grid\nnum_rows = max_images // num_columns + int(max_images % num_columns > 0)  # Calculate the number of rows needed\n\n# Create a grid of subplots\nfig, axes = plt.subplots(num_rows, num_columns, figsize=(15, 6))\n\nfor index in range(len(train_images)):\n    if train_labels[index] == target_label:\n        image = train_images[index]\n        row = count // num_columns\n        col = count % num_columns\n        ax = axes[row, col]\n\n        ax.imshow(image.astype('uint8'))  # Convert to uint8 if needed\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.grid(False)\n        ax.set_title('Label #{} : '.format(train_labels[index]) + class_names_label[train_labels[index]])\n\n        count += 1\n        if count >= max_images:\n            break\nfor i in range(count, num_rows * num_columns):\n    fig.delaxes(axes.flatten()[i])\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels[labels['breed'] == 'shih-tzu']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**One Hot Encoder**","metadata":{}},{"cell_type":"code","source":"train_labels_one_hot = to_categorical(train_labels, num_classes=120)\ntrain_labels_one_hot[0],train_labels[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Spliting Train & Validation ","metadata":{"id":"mo8GHh_ktJ2P"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(train_images, train_labels_one_hot, test_size=0.2, random_state=42)\n\nprint(f\"Training data shape: {X_train.shape}\")\nprint(f\"Validation data shape: {X_val.shape}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = Sequential([\n#     Conv2D(32, (3, 3),input_shape = (224,224,3) , activation='relu'),\n#     MaxPooling2D(2, 2),\n#     Conv2D(64, (3, 3), activation='relu'),\n#     MaxPooling2D(2, 2),\n#     Conv2D(128, (3, 3),  activation='relu'),\n#     MaxPooling2D(2, 2),\n#     Conv2D(256, (3, 3), activation='relu'),\n#     MaxPooling2D(2, 2),\n#     Flatten(),\n#     Dense(512, activation='relu'),\n#     Dropout(0.4),  # Dropout to prevent overfitting\n#     Dense(120, activation='softmax')\n# ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.compile(optimizer=Adam(learning_rate=0.0001), \n#               loss='categorical_crossentropy', \n#               metrics=['accuracy'])\n\n# model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n    rescale=1.0/255.0,\n    horizontal_flip=True,     # Randomly flip half the images horizontally\n    rotation_range=20,        # Random rotations up to 20 degrees\n    width_shift_range=0.2,    # Randomly shift images horizontally by 20%\n    height_shift_range=0.2,   # Randomly shift images vertically by 20%\n    shear_range=0.2,          # Apply random shear transformations\n    zoom_range=[0.9, 1.1],    # Slightly conservative zoom\n    brightness_range=[0.8, 1.2], # Randomly change brightness\n    fill_mode='nearest'       # Fill in new pixels using reflection to avoid artifacts\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen2 = ImageDataGenerator(\n    rescale=1.0/255.0,\n    horizontal_flip=True,     # Randomly flip half the images horizontally\n    zoom_range=[0.9, 1.1],    # Slightly conservative zoom\n    brightness_range=[0.8, 1.2], # Randomly change brightness\n    fill_mode='nearest'       # Fill in new pixels using reflection to avoid artifacts\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## without data augmentation \ndatagen3 = ImageDataGenerator(\n    rescale=1.0/255.0,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_val = X_val / 255.0\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = datagen.flow(X_train, y_train, batch_size=32)\ntrain_generator2 = datagen2.flow(X_train, y_train, batch_size=32)\ntrain_generator3 = datagen3.flow(X_train, y_train, batch_size=32)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Show Some Augmentations","metadata":{}},{"cell_type":"code","source":"def display_augmented_images(datagen, image, num_images=4, grid_size=(2, 2), target_size=(150, 150)):\n    \"\"\"\n    Displays augmented images in a grid layout.\n\n    Parameters:\n        datagen (ImageDataGenerator): The data generator with the augmentation settings.\n        image (numpy array): The image to be augmented.\n        num_images (int): Number of augmented images to display.\n        grid_size (tuple): The size of the grid (rows, cols).\n        target_size (tuple): The target size for resizing the images (height, width).\n    \"\"\"\n    # Ensure the image has the correct shape for the generator\n    img = image.reshape((1,) + image.shape)\n    \n    # Create the grid layout\n    fig, axes = plt.subplots(grid_size[0], grid_size[1], figsize=(8, 8))\n    axes = axes.flatten()  # Flatten the grid to make indexing easier\n    \n    # Generate and plot the images\n    for i, batch in enumerate(datagen.flow(img, batch_size=1)):\n        if i >= num_images:\n            break\n\n        # Normalize the image data to the range [0, 1] if necessary\n        image_to_display = batch[0] / 255.0 if batch[0].max() > 1 else batch[0]\n        \n        # Remove the color channels dimension if it's grayscale\n        if image_to_display.shape[-1] == 1:\n            image_to_display = image_to_display.squeeze()\n\n        # Display the image\n        axes[i].imshow(image_to_display)\n        axes[i].axis('off')  # Hide axes\n    \n    plt.tight_layout()\n    plt.show()\n\n\ndisplay_augmented_images(datagen, X_train[0], num_images=8, grid_size=(4, 2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**try another combination**","metadata":{}},{"cell_type":"code","source":"display_augmented_images(datagen2, X_train[0], num_images=4, grid_size=(2, 2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training & validation loss values\ndef plot_loss(history,model) :\n    plt.figure(figsize=(10, 6))\n    plt.plot(history.history['loss'], label='Train Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.title('Model Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend(loc='upper right')\n    plt.grid(True)\n    plt.show()\n\n    # Evaluate the model\n    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n    print(f\"Validation Loss: {val_loss:.4f}\")\n    print(f\"Validation Accuracy: {val_accuracy:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_acc(history,model) :\n    plt.figure(figsize=(10, 6))\n    plt.plot(history.history['accuracy'], label='Train Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.title('Model Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend(loc='upper right')\n    plt.grid(True)\n    plt.show()\n\n    # Evaluate the model\n    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n    print(f\"Validation Loss: {val_loss:.4f}\")\n    print(f\"Validation Accuracy: {val_accuracy:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transfer Learning ","metadata":{}},{"cell_type":"markdown","source":"**callbacks**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.callbacks import LearningRateScheduler\n\ndef scheduler(epoch, lr):\n    if epoch < 8:\n        return lr\n    else:\n        return lr * float(tf.math.exp(-0.1))\n\nlr_callback = LearningRateScheduler(scheduler)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **InceptionV3**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.optimizers import SGD\n\n\n\ndef train_model_with_generator(train_gen, batch_size=32, epochs=15):\n    # Create a new model\n    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    for layer in base_model.layers:\n        layer.trainable = False\n\n    last_layer = base_model.get_layer('mixed10')\n    last_output = last_layer.output\n    x = GlobalAveragePooling2D()(last_output)\n    x = Dense(1024, activation='relu')(x)\n    x = Dense(120, activation='softmax')(x)\n    \n    # Create the full model\n    model = Model(inputs=base_model.input, outputs=x)\n\n    # Compile the model\n    sgd = SGD(\n    learning_rate=0.001,  # Consider increasing this to 0.001 or 0.01 if training is slow\n    momentum=0.9,\n    nesterov=False,\n    name='SGD'  # Correctly specify the name as a string\n    )\n\n# Compile the model with the SGD optimizer\n    model.compile(\n    optimizer=sgd,\n    loss='categorical_crossentropy',  # Use 'sparse_categorical_crossentropy' if your labels are integers\n    metrics=['accuracy']\n)\n#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    \n    \n    steps_per_epoch = len(X_train) // batch_size  # Number of batches per epoch\n\n\n    # Train the model\n    history = model.fit(\n    train_gen,\n    steps_per_epoch=steps_per_epoch,\n    validation_data=(X_val , y_val),\n    epochs=epochs,\n    callbacks=[early_stopping,lr_callback],\n        )\n\n    \n    return history,model\nhistory1,model = train_model_with_generator(train_generator)\nplot_acc(history1,model)\nplot_loss(history1,model)\n# history2 = train_model_with_generator(train_generator2)\n# plot_acc(history2,model)\n# plot_loss(history2,model)\n# history3 = train_model_with_generator(train_generator3)\n# plot_acc(history3,model)\n# plot_loss(history3,model)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('/kaggle/working/InceptionV3.h5')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\nmodel = load_model('/kaggle/working/InceptionV3.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = (224, 224)\n\ndef load_data(image_dir_test):\n    \"\"\"\n    Load and preprocess the data:\n    - Train images and their labels.\n    - Test images for evaluation.\n    \"\"\"\n\n    def process_images(image_dir):\n        images = []\n        print(\"Loading images from {}\".format(image_dir))\n        for image_file in tqdm(os.listdir(image_dir)):\n            img_path = os.path.join(image_dir, image_file)\n\n            # Open and resize the image\n            image = cv2.imread(img_path)\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n            image = cv2.resize(image, IMAGE_SIZE)\n\n            images.append(image)\n\n        return np.array(images, dtype='float32')\n\n    # Process train images and labels\n    test_images = process_images(image_dir_test)\n    ids = []\n    for image_file in tqdm(os.listdir(image_dir_test)):\n        image_id = image_file.split('.')[0]\n        ids.append(image_id)\n    return test_images, ids\n\n\nimage_dir_test  = '/kaggle/input/dog-breed-identification/test'\ntest_images, ids = load_data(image_dir_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Test images shape: {test_images.shape} \")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(ids)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images = test_images / 255.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(test_images)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_breed = []\nfor i in range(len(predictions)) :\n    predicted_breed.append(class_names_label[np.argmax(predictions[i])])\npredicted_breed[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"breed_names = class_names_label.values() \nbreed_names\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Display Some Predictions","metadata":{}},{"cell_type":"code","source":"def display_predictions(test_images,predicted_breed, num_images=5):\n    \"\"\"\n    Displays a specified number of test images with their predicted breed labels.\n\n    Parameters:\n    - test_images (array-like): Rescaled test images, shape (num_samples, height, width, channels).\n    - predictions (array-like): Predicted class indices for the test images.\n    - predicted_breed (list): List mapping class indices to breed names.\n    - num_images (int): Number of images to display.\n    \"\"\"\n    plt.figure(figsize=(15, 5))  \n\n    for i in range(num_images):\n        plt.subplot(1, num_images, i + 1) \n        image = test_images[i]\n        plt.imshow(image)\n        plt.axis('off') \n        breed_name = predicted_breed[i]\n        plt.title(breed_name, fontsize=12)\n    \n    plt.tight_layout()\n    plt.show()\ndisplay_predictions(test_images,  predicted_breed, num_images=5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission ","metadata":{}},{"cell_type":"code","source":"def create_submission_csv(image_ids, predictions, breed_names, output_file='submission.csv'):\n    \"\"\"\n    Creates a CSV file for submission with columns: id, breed1, breed2, ..., breedN.\n\n    Parameters:\n    - image_ids (list): List of image IDs.\n    - predictions (array-like): 2D array of predicted probabilities, shape (num_samples, num_breeds).\n    - breed_names (list): List of breed names corresponding to the columns.\n    - output_file (str): Name of the output CSV file.\n    \"\"\"\n    # Create a DataFrame with image_ids as the 'id' column\n    df = pd.DataFrame(predictions, columns=breed_names)\n    df.insert(0, 'id', image_ids)  # Insert the 'id' column at the beginning\n    df.to_csv(output_file, index=False)\n    print(f\"CSV file saved as {output_file}\")\ncreate_submission_csv(ids, predictions, breed_names, output_file='submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}